{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "### Neural Machine Translation using word level language model and embeddings in Keras\n",
    "\n",
    "- https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7\n",
    "- https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n",
    "- https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/\n",
    "- https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:21.206430Z",
     "start_time": "2020-09-16T09:48:20.495357Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "from itertools import chain\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from string import digits\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:21.302173Z",
     "start_time": "2020-09-16T09:48:21.240339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (145116, 4)\n",
      "after:  (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desc</th>\n",
       "      <th>Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>and its magnificent trunk , larger than life i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a old curvy tree in the sun light .</td>\n",
       "      <td>and its magnificent trunk , larger than life i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a person is taking a picture of a large tree a...</td>\n",
       "      <td>and its magnificent trunk , larger than life i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large tree with many outstretching branches an...</td>\n",
       "      <td>we found this tree when we were walking in a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a green sign is describing a historic tree and...</td>\n",
       "      <td>it turns out it is a popular attraction here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a large tree with roots that look like crocodi...</td>\n",
       "      <td>the tree is very unusual , with its roots expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>the trunk was really wide , as much as 12 feet !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>huge brown tree roots rose above the ground .</td>\n",
       "      <td>you can see how big these roots are - pretty a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a large tree with many branches coming out</td>\n",
       "      <td>we found this tree when we were walking in a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a plaque describes an historical tree and advi...</td>\n",
       "      <td>it turns out it is a popular attraction here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a tree has spread its roots high and wide acro...</td>\n",
       "      <td>the tree is very unusual , with its roots expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a old curvy tree in the sun light .</td>\n",
       "      <td>the trunk was really wide , as much as 12 feet !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>some trees that are surrounded by apartment bu...</td>\n",
       "      <td>you can see how big these roots are - pretty a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the tree has very long and dated branches .</td>\n",
       "      <td>we found this tree when we were walking in a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a plaque on a stand surround by died leaves of...</td>\n",
       "      <td>it turns out it is a popular attraction here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Desc  \\\n",
       "0      big old tree being photographed on a sunny day   \n",
       "1                 a old curvy tree in the sun light .   \n",
       "2   a person is taking a picture of a large tree a...   \n",
       "3   large tree with many outstretching branches an...   \n",
       "4   a green sign is describing a historic tree and...   \n",
       "5   a large tree with roots that look like crocodi...   \n",
       "6      big old tree being photographed on a sunny day   \n",
       "7       huge brown tree roots rose above the ground .   \n",
       "8          a large tree with many branches coming out   \n",
       "9   a plaque describes an historical tree and advi...   \n",
       "10  a tree has spread its roots high and wide acro...   \n",
       "11                a old curvy tree in the sun light .   \n",
       "12  some trees that are surrounded by apartment bu...   \n",
       "13        the tree has very long and dated branches .   \n",
       "14  a plaque on a stand surround by died leaves of...   \n",
       "\n",
       "                                                Story  \n",
       "0   and its magnificent trunk , larger than life i...  \n",
       "1   and its magnificent trunk , larger than life i...  \n",
       "2   and its magnificent trunk , larger than life i...  \n",
       "3   we found this tree when we were walking in a n...  \n",
       "4      it turns out it is a popular attraction here .  \n",
       "5   the tree is very unusual , with its roots expo...  \n",
       "6    the trunk was really wide , as much as 12 feet !  \n",
       "7   you can see how big these roots are - pretty a...  \n",
       "8   we found this tree when we were walking in a n...  \n",
       "9      it turns out it is a popular attraction here .  \n",
       "10  the tree is very unusual , with its roots expo...  \n",
       "11   the trunk was really wide , as much as 12 feet !  \n",
       "12  you can see how big these roots are - pretty a...  \n",
       "13  we found this tree when we were walking in a n...  \n",
       "14     it turns out it is a popular attraction here .  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "with open('df_story_desc_final.pickle', 'rb') as f:\n",
    "    df_story_and_desc = pickle.load(f)\n",
    "\n",
    "print (\"before: \", df_story_and_desc.shape)\n",
    "df_story_and_desc = df_story_and_desc[:10000]\n",
    "\n",
    "df_story_and_desc_id = df_story_and_desc['Story_Photo_id']\n",
    "df_story_and_desc_text = df_story_and_desc[['Desc', 'Story']]\n",
    "\n",
    "print (\"after: \", df_story_and_desc_text.shape)\n",
    "df_story_and_desc_text.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 15개 단위로 같은 사진 set에 대한 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:21.350046Z",
     "start_time": "2020-09-16T09:48:21.335085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desc</th>\n",
       "      <th>Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>and its magnificent trunk , larger than life i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>the trunk was really wide , as much as 12 feet !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>some more different parts of the tree .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>the trunk was incredibly thick and rigid .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>i was dwarfed by the tree 's size .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Desc  \\\n",
       "0   big old tree being photographed on a sunny day   \n",
       "6   big old tree being photographed on a sunny day   \n",
       "18  big old tree being photographed on a sunny day   \n",
       "24  big old tree being photographed on a sunny day   \n",
       "39  big old tree being photographed on a sunny day   \n",
       "\n",
       "                                                Story  \n",
       "0   and its magnificent trunk , larger than life i...  \n",
       "6    the trunk was really wide , as much as 12 feet !  \n",
       "18            some more different parts of the tree .  \n",
       "24         the trunk was incredibly thick and rigid .  \n",
       "39                i was dwarfed by the tree 's size .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_story_and_desc_text[df_story_and_desc_text.Desc=='big old tree being photographed on a sunny day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:21.413875Z",
     "start_time": "2020-09-16T09:48:21.405898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0 : big old tree being photographed on a sunny day ==> and its magnificent trunk , larger than life itself .\n",
      "pair 6 : big old tree being photographed on a sunny day ==> the trunk was really wide , as much as 12 feet !\n",
      "pair 18 : big old tree being photographed on a sunny day ==> some more different parts of the tree .\n",
      "pair 24 : big old tree being photographed on a sunny day ==> the trunk was incredibly thick and rigid .\n",
      "pair 39 : big old tree being photographed on a sunny day ==> i was dwarfed by the tree 's size .\n"
     ]
    }
   ],
   "source": [
    "for i,row in df_story_and_desc_text[df_story_and_desc_text.Desc=='big old tree being photographed on a sunny day'].iterrows():\n",
    "    print(\"pair\",i,\":\",row['Desc']+\" ==> \"+row['Story'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 하나의 Description Text에 5개의 Story가 대응됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:21.968231Z",
     "start_time": "2020-09-16T09:48:21.954237Z"
    }
   },
   "outputs": [],
   "source": [
    "def re_sub(item):\n",
    "    re_sentence = []\n",
    "    for sentence in item:\n",
    "        sentence = re.sub('[^a-z0-9A-Z]+', ' ', sentence)\n",
    "        re_sentence.append(sentence)\n",
    "    return re_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:22.538078Z",
     "start_time": "2020-09-16T09:48:22.139819Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_desc</th>\n",
       "      <th>out_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big old tree being photographed on a sunny day</td>\n",
       "      <td>&lt;sos&gt; and its magnificent trunk larger than li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a old curvy tree in the sun light</td>\n",
       "      <td>&lt;sos&gt; and its magnificent trunk larger than li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a person is taking a picture of a large tree a...</td>\n",
       "      <td>&lt;sos&gt; and its magnificent trunk larger than li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large tree with many outstretching branches an...</td>\n",
       "      <td>&lt;sos&gt; we found this tree when we were walking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a green sign is describing a historic tree and...</td>\n",
       "      <td>&lt;sos&gt; it turns out it is a popular attraction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>a man in glasses that is standing next to people</td>\n",
       "      <td>&lt;sos&gt; we all visited a winery and took a tour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>people in a room wit ha bottle of wine</td>\n",
       "      <td>&lt;sos&gt; they took us inside and let us see where...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>a man is sniffing a glass of clear champagne</td>\n",
       "      <td>&lt;sos&gt; it was amazing to taste wine while stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>people are seated at a long outside table unde...</td>\n",
       "      <td>&lt;sos&gt; we all sat down together for a meal  &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>a man bending down and petting a cow</td>\n",
       "      <td>&lt;sos&gt; we even got to see the livestock they ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                in_desc  \\\n",
       "0        big old tree being photographed on a sunny day   \n",
       "1                    a old curvy tree in the sun light    \n",
       "2     a person is taking a picture of a large tree a...   \n",
       "3     large tree with many outstretching branches an...   \n",
       "4     a green sign is describing a historic tree and...   \n",
       "...                                                 ...   \n",
       "9995  a man in glasses that is standing next to people    \n",
       "9996             people in a room wit ha bottle of wine   \n",
       "9997       a man is sniffing a glass of clear champagne   \n",
       "9998  people are seated at a long outside table unde...   \n",
       "9999              a man bending down and petting a cow    \n",
       "\n",
       "                                              out_story  \n",
       "0     <sos> and its magnificent trunk larger than li...  \n",
       "1     <sos> and its magnificent trunk larger than li...  \n",
       "2     <sos> and its magnificent trunk larger than li...  \n",
       "3     <sos> we found this tree when we were walking ...  \n",
       "4     <sos> it turns out it is a popular attraction ...  \n",
       "...                                                 ...  \n",
       "9995  <sos> we all visited a winery and took a tour ...  \n",
       "9996  <sos> they took us inside and let us see where...  \n",
       "9997  <sos> it was amazing to taste wine while stand...  \n",
       "9998   <sos> we all sat down together for a meal  <eos>  \n",
       "9999  <sos> we even got to see the livestock they ke...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = df_story_and_desc_text.apply(lambda x: re_sub(x))\n",
    "clean_data.columns = ['in_desc','out_story']\n",
    "clean_data['out_story'] = clean_data['out_story'].apply(lambda x : '<sos> '+ x + ' <eos>')\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "0907 DONE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:23.166348Z",
     "start_time": "2020-09-16T09:48:23.043677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2865, 3486)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_words = set()\n",
    "for desc_paragraph in clean_data.in_desc:\n",
    "    for word in desc_paragraph.split():\n",
    "        if word not in desc_words:\n",
    "            desc_words.add(word)\n",
    "            \n",
    "story_words = set()\n",
    "for story_parapgraph in clean_data.out_story:\n",
    "    for word in story_parapgraph.split():\n",
    "        if word not in story_words:\n",
    "            story_words.add(word)\n",
    "    \n",
    "len(desc_words), len(story_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:23.433578Z",
     "start_time": "2020-09-16T09:48:23.386677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2865\n",
      "Number of unique input tokens: 2865\n",
      "Number of unique output tokens: 3486\n",
      "Max sequence length for inputs: 45\n",
      "Max sequence length for outputs: 47\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(desc_words))\n",
    "target_words = sorted(list(story_words))\n",
    "\n",
    "num_encoder_tokens = len(desc_words)\n",
    "num_decoder_tokens = len(story_words)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt.split(\" \")) for txt in clean_data['in_desc']])\n",
    "max_decoder_seq_length = max([len(txt.split(\" \")) for txt in clean_data['out_story']])\n",
    "\n",
    "print('Number of samples:', len(input_words))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:03:28.557593Z",
     "start_time": "2020-09-16T10:03:28.553630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 47, 3486)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data.out_story), max_decoder_seq_length, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:04:04.921972Z",
     "start_time": "2020-09-16T10:04:04.905020Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(clean_data.in_desc), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(clean_data.out_story), max_decoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(clean_data.out_story), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리 뻑남..\n",
    "\n",
    "MemoryError: Unable to allocate 59.8 GiB for an array with shape (30000, 82, 6524) and data type float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 45)\n",
      "(10000, 47)\n",
      "(10000, 47, 3486)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**why decoder_target_data.shape is 3d**\n",
    "\n",
    "- 모든 단어에 대하여 이전 단어로부터 다음 단어를 예측하는 소프트맥스 층을 가지기 때문에 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "0908 DONE\n",
    "\n",
    "- 왜 1로 초기화 하는가\n",
    "\n",
    "    - ==> 초기화를 1로 하는 것이 아니라 t=0을 건너뛰는 것임\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(clean_data['in_desc'], clean_data['out_story'])):\n",
    "\n",
    "    # encoder\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "\n",
    "    # decoder\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]  \n",
    "        if t > 0: \n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 45)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 47)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  27.,  125., 1676., ...,    0.,    0.,    0.],\n",
       "       [  27.,  125., 1676., ...,    0.,    0.,    0.],\n",
       "       [  27.,  125., 1676., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [  27., 1674., 3347., ...,    0.,    0.,    0.],\n",
       "       [  27., 3368.,   96., ...,    0.,    0.,    0.],\n",
       "       [  27., 3368., 1096., ...,    0.,    0.,    0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (decoder_input_data.shape)\n",
    "decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 47, 3486)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(decoder_target_data.shape)\n",
    "decoder_target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "0909 DONE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build keras encoder-decoder model\n",
    "\n",
    "http://incredible.ai/nlp/2020/02/20/Sequence-To-Sequence-with-Attention/\n",
    "https://docs.chainer.org/en/stable/examples/seq2seq.html\n",
    "\n",
    "https://tykimos.github.io/2018/09/14/ten-minute_introduction_to_sequence-to-sequence_learning_in_Keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "embedding_size = 150 # Embedding Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:  (None, None)\n",
      "en_x:  (None, None, 150)\n",
      "encoder_outputs:  (None, 256)\n",
      "state_h:  (None, 256)\n",
      "state_c:  (None, 256)\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "print('encoder_inputs: ', encoder_inputs.shape)\n",
    "\n",
    "# English words embedding\n",
    "en_x=  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "print('en_x: ', en_x.shape)\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "print('encoder_outputs: ', encoder_outputs.shape)\n",
    "print('state_h: ', state_h.shape)\n",
    "print('state_c: ', state_c.shape)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_inputs:  (None, None)\n",
      "decoder_outputs:  (None, None, 3486)\n"
     ]
    }
   ],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "print('decoder_inputs: ', decoder_inputs.shape)\n",
    "\n",
    "# french word embeddings\n",
    "de_x=  Embedding(num_decoder_tokens, embedding_size)(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences, and to return internal states as well. \n",
    "# We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(de_x,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "print('decoder_outputs: ', decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "0911 DONE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 150)    429750      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 150)    522900      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 416768      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  416768      embedding_3[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 3486)   895902      lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,682,088\n",
      "Trainable params: 2,682,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 45)\n",
      "(10000, 47)\n",
      "(10000, 47, 3486)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 1.3465 - accuracy: 0.0297 - val_loss: 1.5454 - val_accuracy: 0.0324\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 1.2301 - accuracy: 0.0387 - val_loss: 1.4888 - val_accuracy: 0.0421\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 61s 489ms/step - loss: 1.1443 - accuracy: 0.0469 - val_loss: 1.4519 - val_accuracy: 0.0454\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 61s 490ms/step - loss: 1.0810 - accuracy: 0.0516 - val_loss: 1.4308 - val_accuracy: 0.0494\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 1.0259 - accuracy: 0.0549 - val_loss: 1.4160 - val_accuracy: 0.0497\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 60s 479ms/step - loss: 0.9742 - accuracy: 0.0580 - val_loss: 1.4193 - val_accuracy: 0.0509\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.9250 - accuracy: 0.0609 - val_loss: 1.4203 - val_accuracy: 0.0512\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 56s 449ms/step - loss: 0.8772 - accuracy: 0.0642 - val_loss: 1.4297 - val_accuracy: 0.0512\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 55s 441ms/step - loss: 0.8320 - accuracy: 0.0684 - val_loss: 1.4407 - val_accuracy: 0.0510\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 56s 446ms/step - loss: 0.7874 - accuracy: 0.0733 - val_loss: 1.4465 - val_accuracy: 0.0498\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 56s 447ms/step - loss: 0.7420 - accuracy: 0.0795 - val_loss: 1.4597 - val_accuracy: 0.0494\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.6991 - accuracy: 0.0868 - val_loss: 1.4747 - val_accuracy: 0.0489\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 60s 479ms/step - loss: 0.6574 - accuracy: 0.0943 - val_loss: 1.4902 - val_accuracy: 0.0493\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.6166 - accuracy: 0.1024 - val_loss: 1.5049 - val_accuracy: 0.0467\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.5771 - accuracy: 0.1116 - val_loss: 1.5229 - val_accuracy: 0.0470\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.5395 - accuracy: 0.1203 - val_loss: 1.5399 - val_accuracy: 0.0459\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.5039 - accuracy: 0.1290 - val_loss: 1.5555 - val_accuracy: 0.0459\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.4703 - accuracy: 0.1371 - val_loss: 1.5775 - val_accuracy: 0.0462\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.4392 - accuracy: 0.1444 - val_loss: 1.5949 - val_accuracy: 0.0457\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.4100 - accuracy: 0.1513 - val_loss: 1.6167 - val_accuracy: 0.0451\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.3830 - accuracy: 0.1577 - val_loss: 1.6339 - val_accuracy: 0.0445\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.3580 - accuracy: 0.1632 - val_loss: 1.6546 - val_accuracy: 0.0445\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.3354 - accuracy: 0.1682 - val_loss: 1.6707 - val_accuracy: 0.0441\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 56s 451ms/step - loss: 0.3144 - accuracy: 0.1728 - val_loss: 1.6937 - val_accuracy: 0.0437\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 56s 451ms/step - loss: 0.2955 - accuracy: 0.1767 - val_loss: 1.7155 - val_accuracy: 0.0439\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 57s 453ms/step - loss: 0.2780 - accuracy: 0.1803 - val_loss: 1.7420 - val_accuracy: 0.0437\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.2625 - accuracy: 0.1829 - val_loss: 1.7568 - val_accuracy: 0.0438\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.2484 - accuracy: 0.1855 - val_loss: 1.7784 - val_accuracy: 0.0428\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.2360 - accuracy: 0.1878 - val_loss: 1.7946 - val_accuracy: 0.0424\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.2244 - accuracy: 0.1897 - val_loss: 1.8144 - val_accuracy: 0.0418\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.2143 - accuracy: 0.1912 - val_loss: 1.8357 - val_accuracy: 0.0426\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.2056 - accuracy: 0.1925 - val_loss: 1.8540 - val_accuracy: 0.0423\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.1975 - accuracy: 0.1937 - val_loss: 1.8770 - val_accuracy: 0.0425\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.1901 - accuracy: 0.1948 - val_loss: 1.8856 - val_accuracy: 0.0418\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.1836 - accuracy: 0.1959 - val_loss: 1.9057 - val_accuracy: 0.0412\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.1775 - accuracy: 0.1966 - val_loss: 1.9245 - val_accuracy: 0.0411\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.1723 - accuracy: 0.1975 - val_loss: 1.9408 - val_accuracy: 0.0414\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 57s 454ms/step - loss: 0.1672 - accuracy: 0.1981 - val_loss: 1.9537 - val_accuracy: 0.0409\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 58s 460ms/step - loss: 0.1625 - accuracy: 0.1989 - val_loss: 1.9697 - val_accuracy: 0.0408\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 57s 452ms/step - loss: 0.1585 - accuracy: 0.1994 - val_loss: 1.9805 - val_accuracy: 0.0403\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.1544 - accuracy: 0.2000 - val_loss: 1.9997 - val_accuracy: 0.0401\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 0.1506 - accuracy: 0.2006 - val_loss: 2.0089 - val_accuracy: 0.0403\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.1470 - accuracy: 0.2013 - val_loss: 2.0264 - val_accuracy: 0.0403\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.1437 - accuracy: 0.2017 - val_loss: 2.0372 - val_accuracy: 0.0409\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1406 - accuracy: 0.2023 - val_loss: 2.0505 - val_accuracy: 0.0389\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.1374 - accuracy: 0.2029 - val_loss: 2.0622 - val_accuracy: 0.0398\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.1343 - accuracy: 0.2037 - val_loss: 2.0773 - val_accuracy: 0.0394\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 57s 454ms/step - loss: 0.1314 - accuracy: 0.2042 - val_loss: 2.0908 - val_accuracy: 0.0392\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.1284 - accuracy: 0.2048 - val_loss: 2.1026 - val_accuracy: 0.0391\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.1256 - accuracy: 0.2054 - val_loss: 2.1112 - val_accuracy: 0.0385\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.1229 - accuracy: 0.2059 - val_loss: 2.1237 - val_accuracy: 0.0389\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1202 - accuracy: 0.2063 - val_loss: 2.1343 - val_accuracy: 0.0392\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1178 - accuracy: 0.2068 - val_loss: 2.1444 - val_accuracy: 0.0381\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.1153 - accuracy: 0.2075 - val_loss: 2.1529 - val_accuracy: 0.0394\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 58s 464ms/step - loss: 0.1129 - accuracy: 0.2078 - val_loss: 2.1623 - val_accuracy: 0.0383\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.1101 - accuracy: 0.2085 - val_loss: 2.1803 - val_accuracy: 0.0391\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1078 - accuracy: 0.2089 - val_loss: 2.1880 - val_accuracy: 0.0385\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1055 - accuracy: 0.2093 - val_loss: 2.1977 - val_accuracy: 0.0385\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.1030 - accuracy: 0.2099 - val_loss: 2.2050 - val_accuracy: 0.0381\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.1011 - accuracy: 0.2103 - val_loss: 2.2178 - val_accuracy: 0.0380\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 58s 460ms/step - loss: 0.0986 - accuracy: 0.2109 - val_loss: 2.2215 - val_accuracy: 0.0377\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.0966 - accuracy: 0.2112 - val_loss: 2.2318 - val_accuracy: 0.0380\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.0943 - accuracy: 0.2116 - val_loss: 2.2427 - val_accuracy: 0.0381\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0924 - accuracy: 0.2120 - val_loss: 2.2469 - val_accuracy: 0.0371\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 58s 460ms/step - loss: 0.0903 - accuracy: 0.2121 - val_loss: 2.2569 - val_accuracy: 0.0371\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.0879 - accuracy: 0.2131 - val_loss: 2.2730 - val_accuracy: 0.0371\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0863 - accuracy: 0.2130 - val_loss: 2.2774 - val_accuracy: 0.0378\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0844 - accuracy: 0.2135 - val_loss: 2.2813 - val_accuracy: 0.0371\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0825 - accuracy: 0.2137 - val_loss: 2.3001 - val_accuracy: 0.0374\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0806 - accuracy: 0.2143 - val_loss: 2.3052 - val_accuracy: 0.0371\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.0788 - accuracy: 0.2145 - val_loss: 2.3135 - val_accuracy: 0.0376\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0771 - accuracy: 0.2148 - val_loss: 2.3191 - val_accuracy: 0.0378\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.0752 - accuracy: 0.2150 - val_loss: 2.3300 - val_accuracy: 0.0374\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0735 - accuracy: 0.2153 - val_loss: 2.3360 - val_accuracy: 0.0370\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0722 - accuracy: 0.2157 - val_loss: 2.3388 - val_accuracy: 0.0365\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0708 - accuracy: 0.2157 - val_loss: 2.3412 - val_accuracy: 0.0371\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0694 - accuracy: 0.2159 - val_loss: 2.3527 - val_accuracy: 0.0373\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0679 - accuracy: 0.2160 - val_loss: 2.3538 - val_accuracy: 0.0368\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0676 - accuracy: 0.2161 - val_loss: 2.3611 - val_accuracy: 0.0375\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0655 - accuracy: 0.2165 - val_loss: 2.3715 - val_accuracy: 0.0365\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 58s 463ms/step - loss: 0.0641 - accuracy: 0.2166 - val_loss: 2.3781 - val_accuracy: 0.0367\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 0.0629 - accuracy: 0.2167 - val_loss: 2.3798 - val_accuracy: 0.0374\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0616 - accuracy: 0.2168 - val_loss: 2.3908 - val_accuracy: 0.0368\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0603 - accuracy: 0.2170 - val_loss: 2.3977 - val_accuracy: 0.0366\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0594 - accuracy: 0.2171 - val_loss: 2.4056 - val_accuracy: 0.0371\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0584 - accuracy: 0.2173 - val_loss: 2.4105 - val_accuracy: 0.0366\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 0.0576 - accuracy: 0.2173 - val_loss: 2.4178 - val_accuracy: 0.0369\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 57s 454ms/step - loss: 0.0565 - accuracy: 0.2175 - val_loss: 2.4221 - val_accuracy: 0.0371\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.0555 - accuracy: 0.2176 - val_loss: 2.4257 - val_accuracy: 0.0367\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 57s 456ms/step - loss: 0.0545 - accuracy: 0.2178 - val_loss: 2.4324 - val_accuracy: 0.0372\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0538 - accuracy: 0.2178 - val_loss: 2.4370 - val_accuracy: 0.0367\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0531 - accuracy: 0.2178 - val_loss: 2.4462 - val_accuracy: 0.0358\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0521 - accuracy: 0.2180 - val_loss: 2.4484 - val_accuracy: 0.0369\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.0517 - accuracy: 0.2179 - val_loss: 2.4505 - val_accuracy: 0.0378\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0510 - accuracy: 0.2179 - val_loss: 2.4597 - val_accuracy: 0.0373\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0502 - accuracy: 0.2179 - val_loss: 2.4628 - val_accuracy: 0.0371\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0498 - accuracy: 0.2178 - val_loss: 2.4682 - val_accuracy: 0.0367\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0493 - accuracy: 0.2181 - val_loss: 2.4741 - val_accuracy: 0.0369\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 57s 459ms/step - loss: 0.0486 - accuracy: 0.2181 - val_loss: 2.4781 - val_accuracy: 0.0359\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 57s 458ms/step - loss: 0.0482 - accuracy: 0.2181 - val_loss: 2.4812 - val_accuracy: 0.0372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0062216d8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과가.. 이상.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "class AttentionL(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(AttentionL, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        config={'step_dim':self.step_dim}\n",
    "        base_config = super(AttentionL, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11-02  decoder 1 layer\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "display('encoder_inputs: ', encoder_inputs.shape)\n",
    "\n",
    "en_x=  Embedding(num_encoder_tokens, 150)(encoder_inputs)\n",
    "\n",
    "encoder = Bidirectional(LSTM(100, return_state=True,\n",
    "                             dropout = 0.5, recurrent_dropout = 0.5))\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(en_x)\n",
    "\n",
    "# state_h = Concatenate()([forward_h, backward_h])\n",
    "# state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# ### decoder\n",
    "\n",
    "# decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# dex=  Embedding(num_decoder_tokens, EMBEDDING_DIM)\n",
    "\n",
    "# final_dex= dex(decoder_inputs)\n",
    "\n",
    "# decoder_lstm = LSTM(100 * 2, return_sequences=True, return_state=True,\n",
    "#                     dropout = 0.5, recurrent_dropout = 0.5)\n",
    "\n",
    "# print (decoder_lstm(final_dex, initial_state = encoder_states))\n",
    "# decoder_outputs, _, _ = decoder_lstm(final_dex, initial_state = encoder_states)\n",
    "\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "with K.tf.device('/gpu:0'):\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size = 128,\n",
    "              epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model.save(\"1124_bilstm_emb150_model22.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sampling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(units * 2,))  # encoder를 bilstm으로 학습했기 때문에 shape이 50이 아니고 100이다.\n",
    "decoder_state_input_c = Input(shape=(units * 2,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "print (final_dex2)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save\n",
    "# with open('bilstm150_encoder_model_1124.json', 'w', encoding='utf8') as f:\n",
    "#     f.write(encoder_model.to_json())\n",
    "# encoder_model.save_weights('bilstm150_encoder_model_1124.h5')\n",
    "\n",
    "# with open('bilstm150_decoder_model_1124.json', 'w', encoding='utf8') as f:\n",
    "#     f.write(decoder_model.to_json())\n",
    "# decoder_model.save_weights('bilstm150_decoder_model_1124.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "from keras.models import model_from_json\n",
    "def load_model(model_filename, model_weights_filename):\n",
    "    with open(model_filename, 'r', encoding='utf8') as f:\n",
    "        model = model_from_json(f.read())\n",
    "    model.load_weights(model_weights_filename)\n",
    "    return model\n",
    "\n",
    "encoder = load_model('test_bilstm150_encoder_model.json', 'test_bilstm150_encoder_model.h5')\n",
    "decoder = load_model('test_bilstm150_decoder_model.json', 'test_bilstm150_decoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token_index['START_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    #print (\"target_seq: \", target_seq)\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        #print (\"output_tokens: \", output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        #print (\"sampled_token_index: \", sampled_token_index)\n",
    "        #print (\"\")\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 150): # 52\n",
    "            # print (\"Stop_condition = TRUE\")\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_input5000_0 = clean_df_all.description_text[0:5000]\n",
    "df_input5000_1 = clean_df_all.description_text[5000:10000]\n",
    "df_input5000_2 = clean_df_all.description_text[10000:15000]\n",
    "df_input5000_3 = clean_df_all.description_text[15000:20000]\n",
    "df_input5000_4 = clean_df_all.description_text[20000:25000]\n",
    "df_input5000_5 = clean_df_all.description_text[25000:30000]\n",
    "df_input5000_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_story_and_desc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_input_length(start_num, data):\n",
    "    df_input_length = []\n",
    "    for i in range(start_num, start_num + len(data)):\n",
    "        df_input_length.append(i)\n",
    "    return df_input_length\n",
    "\n",
    "df_input5000_0_length = return_input_length(0, df_input5000_0)\n",
    "df_input5000_1_length = return_input_length(5000, df_input5000_1)\n",
    "df_input5000_2_length = return_input_length(10000, df_input5000_2)\n",
    "df_input5000_3_length = return_input_length(15000, df_input5000_3)\n",
    "df_input5000_4_length = return_input_length(20000, df_input5000_4)\n",
    "df_input5000_5_length = return_input_length(25000, df_input5000_5)\n",
    "\n",
    "df_input5000_5_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "# clean_df_all.description_text, clean_df_all.story_text\n",
    "desc_paragraph = []\n",
    "story_paragraph = []\n",
    "#df_input_length_list= [df_input5000_0_length, df_input5000_1_length, df_input5000_2_length, df_input5000_3_length, df_input5000_4_length, df_input5000_5_length]\n",
    "df_input_length_list = [df_input5000_0_length, df_input5000_1_length, df_input5000_2_length]\n",
    "\n",
    "for item in tqdm(df_input_length_list): \n",
    "    for seq_index in item:\n",
    "        input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        #print('-')\n",
    "        #print('Input sentence:', clean_df_all.description_text[seq_index: seq_index + 1])\n",
    "        #print (type(clean_df_all.description_text[seq_index: seq_index + 1]))\n",
    "        desc_paragraph.append(list(df_test_input3.description_text[seq_index: seq_index + 1]))\n",
    "        #print('decoded sentence: ', decoded_sentence)\n",
    "        re_decoded_sentence = re.sub('_END', '', decoded_sentence).strip()\n",
    "        #print('Re decoded sentence:', re_decoded_sentence)\n",
    "        story_paragraph.append(re_decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
