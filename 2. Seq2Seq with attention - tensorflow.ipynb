{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Seq2Seq\n",
    "\n",
    "- https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7\n",
    "- https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n",
    "- https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/\n",
    "- https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "- https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "- https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "- **`encoder`: it processes the input sequence and returns its own internal state.** \n",
    "\n",
    "    - encoder RNN의 아웃풋은 버린다! only recovering the state.\n",
    "    - This state will serve as the \"context\", or \"conditioning\"      \n",
    "    \n",
    "    \n",
    "- **`decoder`: it is trained to predict the next characters of the target sequence, given previous characters of the target sequence.** \n",
    "    - it is trained to **turn the target sequences into the same sequences** \n",
    "    - but offset by one timestep in the future, \n",
    "    - a training process called \"teacher forcing\" in this context. \n",
    "    \n",
    "    - `Importantly, the encoder uses as initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate.` \n",
    "    - Effectively, the decoder learns to generate targets[t+1...] given targets[...t], conditioned on the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:12.012553Z",
     "start_time": "2020-09-29T09:05:10.329068Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:12.119116Z",
     "start_time": "2020-09-29T09:05:12.014192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (602325, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Large tree with many outstretching branches an...</td>\n",
       "      <td>Our landmark tree in town was about to be dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A green sign is describing a historic tree and...</td>\n",
       "      <td>So we decided to take the day to go out and en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A large tree with roots that look like crocodi...</td>\n",
       "      <td>To see the final glimpse of the roots, extendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big old tree being photographed on a sunny day</td>\n",
       "      <td>And its magnificent trunk, larger than life it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huge brown tree roots rose above the ground.</td>\n",
       "      <td>One last picture of its beauty so we could cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Large tree with many outstretching branches an...</td>\n",
       "      <td>We found this tree when we were walking in a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A green sign is describing a historic tree and...</td>\n",
       "      <td>It turns out it is a popular attraction here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A large tree with roots that look like crocodi...</td>\n",
       "      <td>The tree is very unusual, with its roots exposed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big old tree being photographed on a sunny day</td>\n",
       "      <td>The trunk was really wide, as much as 12 feet!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Huge brown tree roots rose above the ground.</td>\n",
       "      <td>You can see how big these roots are - pretty a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Large tree with many outstretching branches an...</td>\n",
       "      <td>Pictures of a tree are taken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A green sign is describing a historic tree and...</td>\n",
       "      <td>The top of the tree is taken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A large tree with roots that look like crocodi...</td>\n",
       "      <td>Another part of the tree mostly the roots.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Big old tree being photographed on a sunny day</td>\n",
       "      <td>Some more different parts of the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Huge brown tree roots rose above the ground.</td>\n",
       "      <td>And some more parts of the tree is taking.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 desc  \\\n",
       "0   Large tree with many outstretching branches an...   \n",
       "1   A green sign is describing a historic tree and...   \n",
       "2   A large tree with roots that look like crocodi...   \n",
       "3      Big old tree being photographed on a sunny day   \n",
       "4        Huge brown tree roots rose above the ground.   \n",
       "5   Large tree with many outstretching branches an...   \n",
       "6   A green sign is describing a historic tree and...   \n",
       "7   A large tree with roots that look like crocodi...   \n",
       "8      Big old tree being photographed on a sunny day   \n",
       "9        Huge brown tree roots rose above the ground.   \n",
       "10  Large tree with many outstretching branches an...   \n",
       "11  A green sign is describing a historic tree and...   \n",
       "12  A large tree with roots that look like crocodi...   \n",
       "13     Big old tree being photographed on a sunny day   \n",
       "14       Huge brown tree roots rose above the ground.   \n",
       "\n",
       "                                                story  \n",
       "0   Our landmark tree in town was about to be dest...  \n",
       "1   So we decided to take the day to go out and en...  \n",
       "2   To see the final glimpse of the roots, extendi...  \n",
       "3   And its magnificent trunk, larger than life it...  \n",
       "4   One last picture of its beauty so we could cap...  \n",
       "5   We found this tree when we were walking in a n...  \n",
       "6       It turns out it is a popular attraction here.  \n",
       "7   The tree is very unusual, with its roots exposed.  \n",
       "8      The trunk was really wide, as much as 12 feet!  \n",
       "9   You can see how big these roots are - pretty a...  \n",
       "10                      Pictures of a tree are taken.  \n",
       "11                      The top of the tree is taken.  \n",
       "12         Another part of the tree mostly the roots.  \n",
       "13             Some more different parts of the tree.  \n",
       "14         And some more parts of the tree is taking.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "with open('dataset/desc_story_data_df.pkl', 'rb') as f:\n",
    "    df_story_and_desc = pickle.load(f)\n",
    "\n",
    "print (\"before: \", df_story_and_desc.shape)\n",
    "# df_story_and_desc = df_story_and_desc[:150000]\n",
    "\n",
    "desc_story_text = df_story_and_desc[['desc', 'story']]\n",
    "desc_story_text.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 15개 단위로 같은 사진 set에 대한 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:12.153931Z",
     "start_time": "2020-09-29T09:05:12.121519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0:Large tree with many outstretching branches and leaves. ==> Our landmark tree in town was about to be destroyed and cleared for a new mall. \n",
      "pair 5:Large tree with many outstretching branches and leaves. ==> We found this tree when we were walking in a nearby town. \n",
      "pair 10:Large tree with many outstretching branches and leaves. ==> Pictures of a tree are taken.\n",
      "pair 15:Large tree with many outstretching branches and leaves. ==> They went to the botanic gardens specifically to see the large tree.\n",
      "pair 20:Large tree with many outstretching branches and leaves. ==> We went to see the largest tree in the country. \n"
     ]
    }
   ],
   "source": [
    "check_sent = \"Large tree with many outstretching branches and leaves.\"\n",
    "for i, row in desc_story_text[desc_story_text['desc'] == check_sent].iterrows():\n",
    "    print(\"pair \" + str(i) + \":\" + row['desc'] + \" ==> \" + row['story'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 하나의 Description Text에 5개의 Story가 대응됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:13.290141Z",
     "start_time": "2020-09-29T09:05:13.284824Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_duplicate(df):\n",
    "    drop_df = df.drop_duplicates(\"desc\")\n",
    "    drop_df = drop_df.drop_duplicates(\"story\")\n",
    "    drop_df = drop_df.reset_index(drop=True)\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:13.622737Z",
     "start_time": "2020-09-29T09:05:13.501184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39771, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_story_text = drop_duplicate(desc_story_text)\n",
    "desc_story_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess text\n",
    "\n",
    "- Add a start and end token to each sentence.\n",
    "- Clean the sentences by removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:14.547024Z",
     "start_time": "2020-09-29T09:05:14.541203Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = re.sub('[^a-zA-Z]+', ' ', w)\n",
    "    w = re.sub('[^a-zA-Z.,!?]+', ' ', w)\n",
    "    w = w.strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:15.290271Z",
     "start_time": "2020-09-29T09:05:14.765919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_desc</th>\n",
       "      <th>out_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; Large tree with many outstretching bra...</td>\n",
       "      <td>&lt;start&gt; Our landmark tree in town was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; A green sign is describing a historic ...</td>\n",
       "      <td>&lt;start&gt; So we decided to take the day to go ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; A large tree with roots that look like...</td>\n",
       "      <td>&lt;start&gt; To see the final glimpse of the roots ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; Big old tree being photographed on a s...</td>\n",
       "      <td>&lt;start&gt; And its magnificent trunk larger than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; Huge brown tree roots rose above the g...</td>\n",
       "      <td>&lt;start&gt; One last picture of its beauty so we c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39766</th>\n",
       "      <td>&lt;start&gt; AN ADVERTISEMENT ON GLASS FOR A BREWIN...</td>\n",
       "      <td>&lt;start&gt; A group of friends visited a brewery &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>&lt;start&gt; A man holds the woman s hand under the...</td>\n",
       "      <td>&lt;start&gt; They were very excited &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>&lt;start&gt; A young man and older woman sitting do...</td>\n",
       "      <td>&lt;start&gt; They sampled many different beers &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>&lt;start&gt; An elderly couple dances outside of a ...</td>\n",
       "      <td>&lt;start&gt; After becoming a little buzzed they ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>&lt;start&gt; Man and two women standing at a counte...</td>\n",
       "      <td>&lt;start&gt; They had a great time and claimed that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39771 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 in_desc  \\\n",
       "0      <start> Large tree with many outstretching bra...   \n",
       "1      <start> A green sign is describing a historic ...   \n",
       "2      <start> A large tree with roots that look like...   \n",
       "3      <start> Big old tree being photographed on a s...   \n",
       "4      <start> Huge brown tree roots rose above the g...   \n",
       "...                                                  ...   \n",
       "39766  <start> AN ADVERTISEMENT ON GLASS FOR A BREWIN...   \n",
       "39767  <start> A man holds the woman s hand under the...   \n",
       "39768  <start> A young man and older woman sitting do...   \n",
       "39769  <start> An elderly couple dances outside of a ...   \n",
       "39770  <start> Man and two women standing at a counte...   \n",
       "\n",
       "                                               out_story  \n",
       "0      <start> Our landmark tree in town was about to...  \n",
       "1      <start> So we decided to take the day to go ou...  \n",
       "2      <start> To see the final glimpse of the roots ...  \n",
       "3      <start> And its magnificent trunk larger than ...  \n",
       "4      <start> One last picture of its beauty so we c...  \n",
       "...                                                  ...  \n",
       "39766  <start> A group of friends visited a brewery <...  \n",
       "39767               <start> They were very excited <end>  \n",
       "39768    <start> They sampled many different beers <end>  \n",
       "39769  <start> After becoming a little buzzed they ev...  \n",
       "39770  <start> They had a great time and claimed that...  \n",
       "\n",
       "[39771 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = desc_story_text.copy()\n",
    "clean_data['desc'] = desc_story_text['desc'].apply(lambda x: preprocess_sentence(x))\n",
    "clean_data['story'] = desc_story_text['story'].apply(lambda x: preprocess_sentence(x))\n",
    "clean_data.columns = ['in_desc','out_story']\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:15.358745Z",
     "start_time": "2020-09-29T09:05:15.353507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Large tree with many outstretching branches and leaves <end>\n",
      "<start> Our landmark tree in town was about to be destroyed and cleared for a new mall <end>\n"
     ]
    }
   ],
   "source": [
    "print(clean_data[\"in_desc\"][0])\n",
    "print(clean_data[\"out_story\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Padding\n",
    "\n",
    "- Create a word index and reverse word index (dictionaries mapping from word → id and id → word).   \n",
    ": 단어 색인과 역방향 단어 색인을 만듭니다 (단어 → ID 및 ID → 단어에서 매핑 된 사전).\n",
    "\n",
    "- Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:16.387938Z",
     "start_time": "2020-09-29T09:05:16.379201Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(input_desc, output_story, flag):\n",
    "    '''Args flags : pre / post 차이 \n",
    "    '''\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    \n",
    "    if flag == \"input\":\n",
    "        tokenizer.fit_on_texts(input_desc)\n",
    "        # sentence 최대 길이로 패딩 자동으로 해줌\n",
    "        input_seq = tokenizer.texts_to_sequences(input_desc)\n",
    "        padding_flag = 'post'\n",
    "#        padding_flag = 'pre' # input은 앞에서 0을 채움\n",
    "        input_pad_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding=padding_flag)\n",
    "        \n",
    "        return input_pad_seq, tokenizer\n",
    "    else:\n",
    "        tokenizer.fit_on_texts(output_story)\n",
    "        output_seq = tokenizer.texts_to_sequences(output_story)\n",
    "        padding_flag = 'post' # output은 뒤에서 0을 채움\n",
    "        output_pad_seq = tf.keras.preprocessing.sequence.pad_sequences(output_seq, padding=padding_flag)\n",
    "    \n",
    "        return output_pad_seq, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:17.117731Z",
     "start_time": "2020-09-29T09:05:17.108773Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_token_data(data):\n",
    "    # creating cleaned input, output pairs\n",
    "    input_desc, output_story = data['in_desc'], data['out_story']\n",
    "    \n",
    "    tokenize_input_desc, input_tokenizer = tokenize(input_desc, output_story, \"input\")\n",
    "    tokenize_output_story, output_tokenizer= tokenize(input_desc, output_story, \"output\")\n",
    "    \n",
    "    input_desc_train, input_desc_test, output_story_train, output_story_test = train_test_split(tokenize_input_desc, tokenize_output_story, test_size=0.2)\n",
    "    \n",
    "    print(\"input_desc_train: \", input_desc_train.shape)\n",
    "    print(\"input_desc_test: \", input_desc_test.shape)\n",
    "    print(\"output_story_train: \", output_story_train.shape)\n",
    "    print(\"output_story_test: \", output_story_test.shape)\n",
    "    \n",
    "    return input_desc_train, input_desc_test, output_story_train, output_story_test, input_tokenizer, output_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:19.302707Z",
     "start_time": "2020-09-29T09:05:17.491358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_desc_train:  (31816, 72)\n",
      "input_desc_test:  (7955, 72)\n",
      "output_story_train:  (31816, 77)\n",
      "output_story_test:  (7955, 77)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "\n",
    "input_desc_train, input_desc_test, output_story_train, output_story_test, input_tokenizer, output_tokenizer = get_token_data(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:19.307572Z",
     "start_time": "2020-09-29T09:05:19.304267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,  523,   46, ...,    0,    0,    0],\n",
       "       [   2,    1,  225, ...,    0,    0,    0],\n",
       "       [   2,    1,   16, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,    1,   16, ...,    0,    0,    0],\n",
       "       [   2,   18, 1428, ...,    0,    0,    0],\n",
       "       [   2,    1,   41, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_desc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:19.315055Z",
     "start_time": "2020-09-29T09:05:19.309247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   21,   54, ...,    0,    0,    0],\n",
       "       [   1,   42,   14, ...,    0,    0,    0],\n",
       "       [   1,   23, 2910, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,    9,  166, ...,    0,    0,    0],\n",
       "       [   1,   66,    3, ...,    0,    0,    0],\n",
       "       [   1,   21,   14, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_story_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T09:05:19.323326Z",
     "start_time": "2020-09-29T09:05:19.316620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 8, 41, 82, 97, 164, 194, 328, 388, 776, 3977, 7954, 15908, 31816]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 단위가 0으로 떨어지게끔 최소공약수 계산해서 배치 설정 숫자 구함\n",
    "\n",
    "def get_divisor(num):\n",
    "    divisors = []\n",
    "    length = int(math.sqrt(num)) + 1\n",
    "    for i in range(1, length):\n",
    "        if num % i == 0:\n",
    "            divisors.append(i)\n",
    "            divisors.append(num // i) # 나누기 연산 후 정수부분만 구하기,\n",
    "\n",
    "    divisors.sort()\n",
    "\n",
    "    return divisors\n",
    "\n",
    "get_divisor(len(input_desc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_desc_train)\n",
    "BATCH_SIZE = 164\n",
    "steps_per_epoch = len(input_desc_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(input_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(output_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_desc_train, output_story_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13341, 14192)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size, vocab_tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T05:16:00.985517Z",
     "start_time": "2020-10-03T05:16:00.977109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "\n",
    "# prefetch = gpu에 올라갈 데이터 slices\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((input_desc_train, output_story_train)).shuffle(len(input_desc_train)).batch(BATCH_SIZE).prefetch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((input_desc_test, output_story_test)).batch(1) # 하나씩 출력하기 위해서 batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([164, 72]), TensorShape([164, 77]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train_ds))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the encoder and decoder model with attention\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:\n",
    "\n",
    "**Reference**\n",
    "- https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "- https://heung-bae-lee.github.io/2020/01/22/deep_learning_11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,  # output을 3차원으로 반환 (batch, sequence_length, #units)\n",
    "                                       return_state=True, # returns the hidden state output and cell state for the last input time step\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (164, 72, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (164, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "바다나우 어텐션 설명 참고\n",
    "\n",
    "https://www.youtube.com/watch?v=WsQLdu2JMgI\n",
    "\n",
    "![](imgs/bahdanauAttention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units) # time step 별 hidden state\n",
    "        self.W2 = tf.keras.layers.Dense(units) # decoder hidden state \n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1) # expand_dims를 통해 encoder의 hidden state들을 합쳐줌\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values))) #FC(tanh(FC(h1,h2,h3)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (164, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (164, 72, 1)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output) \n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (164, 14192)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T10:27:41.489869Z",
     "start_time": "2020-09-29T09:05:30.051079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T05:07:47.110167Z",
     "start_time": "2020-10-03T05:07:47.104984Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T05:16:09.833751Z",
     "start_time": "2020-10-03T05:16:08.178507Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([output_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
